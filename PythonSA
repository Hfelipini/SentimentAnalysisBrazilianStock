""" #Pacotes para serem instalados antes de rodar o programa
#pip install requests_oauthlib --user
#pip install twython --user
#pip install nltk --user
#pip install pyspark --user
"""

#Cassandra & Postgres

""" #Linhas de Comando para Conectar, Inserir e Ler Dados da base de dados no Cassandra DB no Docker
from cassandra.cluster import Cluster
try: 
    cluster = Cluster(['127.0.0.1'], port=6000) #If you have a locally installed Apache Cassandra instance
    session = cluster.connect()
    print(session)
except Exception as e:
    print(e)

session.execute("CREATE KEYSPACE IF NOT EXISTS test WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };")
session.execute("USE test;")

#session.execute("CREATE TABLE test.user_data (user_id int PRIMARY KEY, user_name text, city text);")
#session.execute("INSERT INTO user_data (user_id, user_name, city) VALUES (7, 'Henrique', 'Floripa')")
#session.execute("INSERT INTO user_data (user_id, user_name, city) VALUES (8, 'Ram', 'Bangalore');")
#session.execute("INSERT INTO user_data (user_id, user_name, city) VALUES (9, 'Shiva', 'Hyderabad');")
i = 10
j = 'Gy'
k = 'BC'
session.execute("INSERT INTO user_data (user_id, user_name, city) VALUES (%s,%s,%s);",(i,j,k))
rows=session.execute("SELECT * FROM user_data;")
for user_row in rows:
        print(user_row.user_id, user_row.user_name, user_row.city)

#Cluster.shutdown()
"""

""" #Linhas de Comando para Conectar, Inserir e Ler Dados da base de dados no Postgres DB no Docker
# Docker -> Postgres -> Terminal
# Comando Terminal: "psql -d postgres -U postgres"
# "\l" listar databases
# Comando Terminal: "use postgres"
# "\dt"
# Listas todas as tabelas
# Comando Terminal: "SELECT * FROM user_data;" -> Retorna todos os dados na tabela criada e populada

import psycopg2
conn = psycopg2.connect("host=127.0.0.1 port=7000 dbname=postgres user=postgres password=example")
print(conn)

cursor = conn.cursor()

#def create_user(nome,email,senha):
#  cursor.execute("INSERT INTO usuario (nome,email,senha) VALUE (%s,%s,%s);", (nome,email,senha))

#def find_all():
#  return cursor.fetchall()

#cursor.execute("DROP TABLE IF EXISTS user_data")
#cursor.execute("CREATE TABLE user_data (user_id int PRIMARY KEY, user_name CHAR(100), city CHAR(100))")
#i = 10
#j = 'Gy'
#k = 'BC'
#cursor.execute("INSERT INTO user_data VALUES (%s, %s, %s);",(i,j,k)) 
cursor.execute("SELECT * FROM user_data")
get_all_data = cursor.fetchall()
print(get_all_data[0][1])

conn.commit()
#cursor.execute("CREATE TABLE user_data  ;")

conn.close()
"""

 #Código para ler e gerar infos de Tweets no Twitter
#Módulos Usados
import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

# Twitter API credentials
consumerKey = 'jZW6Dfje4Qf2qQcseMN8oWK6L'
consumerSecret = 'aQEHFWJhmx1wuTJFSHH7hXbsYf5FZ2ks2HgUOkefsL14DfRmqd'
accessToken = '849412140767342593-lqu60Ceu6VgSWSyUkolOHIf8fUVMVVs'
accessTokenSecret = 'aHpBV2133OHN2vLpp2RERBhZaCq6jaJa3iyZw0tVQ4mzh'

print("Oi1")

#Frequencia Update
authenticate = tweepy.OAuthHandler(consumerKey, consumerSecret)

#Set the access token and access token secret
authenticate.set_access_token(accessToken, accessTokenSecret)

# Create the API Object while passing in the auth information
api = tweepy.API(authenticate, wait_on_rate_limit = True)

print("Oi2")

autores = ["AlexSchwartsman", "RaphaFigueredo", "goescarlos", "terracoecon", "infomoney", "Tiagogreis", "cafecomferri", "FariaLimaElevat", "helocruz", "sf2invest", "PabloSpyer"]

for aut in range(0, len(autores)):
  posts = api.user_timeline(screen_name =autores[aut], count= 100, lang = "en", tweet_mode="extended")
  user = api.get_user(screen_name =autores[aut])
  ID = user.id_str

  # Print the last 5 tweets from the account
  print("Show the 5 recent tweets: \n")
  i = 1
  for tweet in posts[0:5]:
      #print(str(i) + ')' + ID + " " + tweet.id_str + " " + tweet.full_text + '\n')
      print(str(i) + ')' + ID + " " + str(tweet.id) + " " + str(tweet.created_at) + " " + tweet.full_text + '\n')
      i = i + 1 
  #aut = aut + 1
  #print(aut)

print("Oi3")


# Extract 100 tweets from the twitter user
"""
posts = api.user_timeline(screen_name ="BillGates", count= 100, lang = "en", tweet_mode="extended")
user = api.get_user(screen_name ="BillGates")
ID = user.id_str

# Print the last 5 tweets from the account
print("Show the 5 recent tweets: \n")
i = 1
for tweet in posts[0:5]:
    #print(str(i) + ')' + ID + " " + tweet.id_str + " " + tweet.full_text + '\n')
    print(str(i) + ')' + ID + " " + str(tweet.id) + " " + str(tweet.created_at) + " " + tweet.full_text + '\n')
    i = i + 1 

print("Oi3")

#Create a dataframe with a column called Tweets
df = pd.DataFrame( [tweet.full_text for tweet in posts], columns=['Tweets'])

#show the first 5 rows of data
df.head()

print("Oi4")

#Clean the text

#Create a function to clean the tweets
def cleanTxt(text):
    text = re.sub(r'@[A-Za-z0-9]+', '', text) #Removed @mentions
    text = re.sub(r'#', '', text) #Removed the Hashtag
    # Ideia de utilizar o re.sub e filtrar por todos os tweets que estejam falando de alguma ação em especifico no momento
    text = re.sub(r'RT[\s]+', '', text) #Removed RT
    text = re.sub(r'https?:\/\/S+', '', text) #Removed the hyper link
    return text

# Cleaning the text
df['Tweets'] = df['Tweets'].apply(cleanTxt)

#Show the cleaned text
df.head()

print("Oi5")

#Create a function to get the subjectivity
def getSubjectivity(text):
    return TextBlob(text).sentiment.subjectivity

#Create a function to get the polarity
def getPolarity(text):
    return TextBlob(text).sentiment.polarity

#Create two new columns
df['Subjectivity'] = df['Tweets'].apply(getSubjectivity)
df['Polarity'] = df['Tweets'].apply(getPolarity)

#Show the new dataframe with the new columns
df.head()

print("Oi6")

#Plot the Word Cloud
allWords = ' '.join( [twts for twts in df['Tweets']] )
wordCloud = WordCloud(width = 500, height = 300, random_state = 21, max_font_size = 119).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis("off")
plt.show()

print("Oi7")

#Create a function to compute the negative, neutral and positive analysis
def getAnalysis(score):
  if score < 0:
    return 'Negative'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positive'

df['Analysis'] = df['Polarity'].apply(getAnalysis)

#print(df)

print("Oi8")

# Print All of the negative tweets
j=1
sortedDF = df.sort_values(by=['Polarity'], ascending = False)
for i in range(0, sortedDF.shape[0]):
  if (sortedDF['Analysis'][i] == 'Negative'):
    print(str(j) + ') ' + sortedDF['Tweets'][i])
    print()
    j = j+1

print("Oi9")

#Plot the polarity and subjectivity
plt.figure(figsize=(8,6))
for i in range(0, df.shape[0]):
  plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color='Blue')

plt.title('Sentiment Analysis')
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')

print("Oi10")

#Get the percentage of positive tweets
ptweets = df[df.Analysis == 'Positive']
ptweets = ptweets['Tweets']

round((ptweets.shape[0]/df.shape[0])*100,1)
print("Oi11")

#Get the percentage of negative tweets
ntweets = df[df.Analysis == 'Negative']
ntweets = ntweets['Tweets']

round((ntweets.shape[0]/df.shape[0])*100,1)
print("Oi12")

#Show the value counts

df['Analysis'].value_counts()

#Plot and visualize the counts
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
df['Analysis'].value_counts().plot(kind='bar')
plt.show()
print("Oi13")
"""
